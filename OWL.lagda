\documentclass{llncs}


%%%%%%%%%%%%%%%%% Preamble %%%%%%%%%%%%%%%%%%%%%%%

%% Fix Margins 
%\usepackage[margin=1in]{geometry}

\usepackage{listings}
\usepackage{amsfonts}
\usepackage{xcolor}
\usepackage{graphicx}

% Equations
\usepackage{amsmath}

% Fonts
\usepackage{amssymb}
\usepackage{bbm}
\usepackage[greek,english]{babel}
\usepackage{textgreek}
\usepackage{stmaryrd}

%% This handles the translation of unicode to latex:
%\usepackage{ucs}
\usepackage[utf8x]{inputenc}
\usepackage{autofe}

%% Some convenient shorthands
\newcommand{\AD}{\AgdaDatatype}
\newcommand{\AF}{\AgdaFunction}
\newcommand{\AB}{\AgdaBound}
\newcommand{\AIC}{\AgdaInductiveConstructor}
\newcommand{\AM}{\AgdaModule}
\newcommand{\AP}{\AgdaPrimitive}
\newcommand{\AS}{\AgdaString}
\newcommand{\AR}{\AgdaRecord}
\newcommand{\AK}{\AgdaKeyword}
\newcommand{\AO}{\AgdaOperator}
% Better use this one!

\usepackage{agda}
%include agda.fmt

\usepackage{bussproofs}

%% Lambda Calculus (should be a .sty at some point) 
\definecolor{typeColour}              {HTML}{0000CD}
\definecolor{judgementColour}         {HTML}{008B00}

\newcommand{\atype}[1]{\textcolor{typeColour}{#1}}

\newcommand{\ofty}[2]{{#1}{:}{#2}}
%\newcommand{\ofty}[2]{{#1}\colon\kern-.15em{#2}}
\newcommand{\bigofty}[2]{{#1} \textcolor{judgementColour}{\;:\;} { \atype{#2} }}
\newcommand{\lam}[3]{\lambda(\ofty{#1}{ \atype{#2} }).{#3}}
\newcommand{\app}[2]{{#1}\circ{#2}}
\newcommand{\bred}{\;\Rightarrow_{\beta}\;}
\newcommand{\subst}[2]{ [{#1} := {#2}] }

\newcommand{\seq}[3]{{#1} \textcolor{judgementColour}{\;\vdash\;} \bigofty{#2}{#3} }

\newcommand{\oseq}[2]{{#1} \textcolor{judgementColour}{\;\vdash\;} {#2}}

\newcommand{\imp}[2]{{#1} \rightarrow {#2}}

\newcommand{\impElim}{$E^{\rightarrow}$}


%% Some characters that are not automatically defined
%% (you figure out by the latex compilation errors you get),
%% and you need to define:
%
%\DeclareUnicodeCharacter{8988}{\ensuremath{\ulcorner}}
%\DeclareUnicodeCharacter{8989}{\ensuremath{\urcorner}}
%\DeclareUnicodeCharacter{8803}{\ensuremath{\overline{\equiv}}}
\DeclareUnicodeCharacter{8799}{\ensuremath{\stackrel{{!!}}{=}}}
\DeclareUnicodeCharacter{8759}{\ensuremath{\colon\colon}}
\DeclareUnicodeCharacter{7477}{\ensuremath{^{I}}}
\DeclareUnicodeCharacter{7472}{\ensuremath{^{D}}}
\DeclareUnicodeCharacter{7580}{\ensuremath{^{C}}}
\DeclareUnicodeCharacter{7488}{\ensuremath{^{T}}}
\DeclareUnicodeCharacter{7480}{\ensuremath{^{L}}}
\DeclareUnicodeCharacter{7486}{\ensuremath{^{P}}}
\DeclareUnicodeCharacter{7484}{\ensuremath{^{O}}}
\DeclareUnicodeCharacter{7584}{\ensuremath{^{F}}}
\DeclareUnicodeCharacter{7468}{\ensuremath{^{A}}}
\DeclareUnicodeCharacter{2208}{\ensuremath{\in}}
%% Add more as you need them (shouldn’t happen often). 

%% Hyper ref for \url support
\usepackage{hyperref}

%%%%%%%%%%%%%%%%%%% Paper %%%%%%%%%%%%%%%%%%%%%%%%%%


\title{Machine Checkable Formalisation of OWL semantics}
\author{Gavin Mendel-Gleason and Rob Brennan and Kevin Feeney} 

\begin{document}

\maketitle 

%% 1. Who are the intended readers(3-5 names)
%% 2. What did you do?(50 words)
%% 3. Why did you do that?(50 words) - why did it need to be done in the field?
%% 4. What happened when you did it? (50 words)
%% 5. What do the results mean in theory(50 words)
%% 6. What  do the results mean in practice(50 words)
%% 7. (NB most impt q) What is the key benefit for readers?(25 words)
%% 8. What remains unresolved (no word limit)

\begin{abstract} We provide a type theoretic semantics for OWL in the Agda
proof-assistant.  By {\em type theoretic semantics} we mean that we
construct a type in a Martin L{\"o}f style type theory which
represents a given axiom description in the semantics of OWL DL
which mirrors the direct semantics.  We may then show that a given OWL
description is sound in a machine checkable proof.  We demonstrate an
OWL ontology and show that it, coupled with data, is verifiably
correct.  Reasoners using this formalisation can show, by
construction, that the models they produce satisify OWL's semantics.
Alternatively, this provides a new means to test the correctness of
reasoners against a set of proof-obligations generated by this
technique.  This will enable novel hybrid reasoners that include both
automated and hand-crafted but provably correct solutions for specific
ontologies.
\end{abstract}

\section{Introduction}

OWL has increasingly become the tool of choice for the representation
of ontologies in many industries and scientific areas.  However, the
exploitation of OWL ontologies requires reasoners.

% The meaning of OWL ontologies can be explored with a
% reasoner\cite{Tai2015Resourceconstrained}.  These reasoners attempt to
% find a {\em model} for the given {\em axiom description} of the
% ontology.  If a model is found then the ontology is consistent.

OWL reasoners\cite{Tai2015Resourceconstrained} are generally written
by hand and the connection with the actual OWL semantics is only
judged to be correct by assuming the implementation correctness of the
reasoner.  This is generally established by standard software testing
approaches\cite{babik2008testing}.  In this case OWL's semantics does
not provably constrain the implementation correctness of the reasoner.

% In this scenario OWL's Full semantics remains on paper and does not
% directly contribute to the correctness of the reasoner, the
% correctness of which must be assessed by other methods.

% Research question

This leads to the following research question: to what extent is it
possible to verify the implementation correctness of OWL reasoners
with respect to the OWL semantics?

% Technical approach

Martin L{\"o}f Type Theory (MLTT) \cite{martin1984intuitionistic}
provides a foundation for formal reasoning for software and
mathematics.  Agda is a programming language of dependent
types\cite{norell2009dependently} which doubles as a proof-assistant
and which uses an MLTT-style type system.  In this paper we
demonstrate how the OWL DL semantics\cite{2012OWL} can be expressed in
an MLTT-style theory using the Agda language.  This approach provides
us with the proof obligations which must be satisfied in order to show
that the OWL ontology is consistent.  Proof obligations could be, for
example, a set of subsumption relationships inferred from the
ontology.  We can then verify the implementation correctness for this
ontology of any reasoner which can fill these proof obligations. The
Agda compiler's ability to type-check and load the file serves en lieu
of a written formal proof - one who's correctness is reduced to trust
in Agda's type theory. In order to read the paper it is useful to have
some familiary with Agda's syntax as given in
\cite{norell2009dependently}.

The contribution of this paper is a new technique for proving
correctness of reasoners and a formal description of OWL DL in type
theory. In our paper we demonstrate proof obligations by hand, but
decidable reasoners could produce these automatically, either by
writing a total function of appropriate type within Agda itself, or by
an offline process in which a reasoner produces the evidence required
of the proof obligations, which can then be checked by Agda.  This
later process could be used as a test-harness or verification step of
correctness of reasoners which are not written in Agda.  In addition
our technique allows for the possibility of proving correctness for
ontologies that are challenging for reasoners to handle - for
instance, ones that do not fit into a known decidable fragment.  In
this case the proof of correctness can be supplied by hand.

The structure of this paper is presented in a {\em literate
  programming} style\cite{knuth1992literate}.  This approach is a good
fit for describing mechanisations of semantics, as the description of
the mechanisation is kept in tight correspondence with the proof
itself and has become a standard practice in machine reasoning.  The
LaTeX file (which can be found here\cite{MendelGleason2015OWL})
contains the complete programme (though not all of it is visible in
the printed version), and type-checks cleanly, providing verification
of correctness of all the content presented.

We first present prior work which is related to fulfilling correctness
criteria for semantic descriptions in Section~\ref{PriorWork}.  In
Section~\ref{Sets} we briefly show how set-like objects can be
represented in a type theory such that the OWL direct semantics is
followed quite closely.  We then show the manner in which OWL
descriptions are represented in Agda as a datatype in
Section~\ref{OWLSemantics}.  In this paper we write OWL axioms
explicitly using the data types presented, but it is quite possible to
generate these automatically from a file of OWL descriptions in RDF or
Turtle.  We then present the mapping of these descriptions to the
semantics of OWL Full in Section~\ref{Interpretation}.  After this we
present an example of an OWL axiom description coupled with some
interpretation functions, obtain the proof obligations as a type and
then show that these proof obligations can be met for the given OWL
axiom description in Section~\ref{Example}.  Finally we will present
directions and future work in Section~\ref{Conclusion}.

\section{Prior Work}
\label{PriorWork}

To the authors' knowledge, no prior work has been done on formalising
OWL semantics in a type theory.  We believe such a formalisation is an
important contribution, not least because type theory is enjoying
growing acceptance as a foundational discipline for mathematics and as
a replacement for set theory, which is the foundational framework in
which OWL's direct semantics is given.  Type theory has demonstrated
several advantages (and disadvantages) over set theory, but the
primary advantage the authors are concerned with is machine checkable
proofs such as the one provided in this paper.

However, the aims of our formalisation, which are to show that OWL
ontologies are consistent and to demonstrate the correctness of this
determination, have been reached by other means in prior work.

In most cases, consistency of ontologies is provided by utilisation of
a reasoner.  A large number of reasoners for OWL are
available\cite{abburu2012survey}.  These generally choose a decidable
fragment of OWL to implement to ensure that reasoning will eventually
terminate\cite{krotzsch2012owl}.  The correctness of the reasoner is
supported by some testing framework (as in \cite{babik2008testing}).

Our approach differs from the software testing approach as it bases
correctness on the {\em certified programme}
approach\cite{chlipala2011certified}.  The {\em certificate} of
correctness is supplied by a {\em type checker} which is a small piece
of software which performs the check of type correctness over a
suitably rich language which can be used to encode a large class of
problems.  The type-checking algorithm is generally designed to be
decidable (though not always\cite{augustsson1998cayenne}), whereas the
problem spaces in which the encoding of the proof is made need not be.

This reduces correctness of very complex problems which can be given
type-correct proofs to the correctness of the certifying programme and
leaves the mechanism for finding the proof as an exercise to the human
practitioner or automated theorem prover.  Since the certifying
programme is re-used on a large class of problems and the code which
implements it is relatively small, we can hope for a greater level of
trust in the correctness of the outcome.

In the type-theory community there are examples of approaches which
use type theory to perform software testing\cite{dybjer2003combining}
as well.  This approach might prove fruitful for OWL reasoners.

The possibility of transcript proofs which can be generated offline by
a reasoner and then checked using the type-checker to certify the
proof has been explored in \cite{zhuangcombining}.  Our suggestion
that this could be used for reasoners in OWL is advanced by our
formalisation of the OWL semantics.

\section{Sets in Type Theory}
\label{Sets}

Martin L{\"o}f style type theories provide a foundational framework
for the exploration of mathematics.  They are however somewhat
different from set theory and so a little bit of boilerplate is
necessary to conveniently represent objects which are familiar to
those who work with set theory.

One way to represent many of the set operations which are present in
set theory is to create a family of {\em unary} predicates over a type
(See Chapter 18 of \cite{nordstrom1990programming}).  This allows us
to express element inclusion as well as form the familiar union,
intersection and various other operations. Agda provides a library
which gives us tools to work with this approach. However, we
demonstrate a slightly simpler version to give an idea of how the
approach works. We build our example inside of a record so as to
parameterise over a generic {\em small} set $\AB{A}$.

Agda somewhat confusingly calls types $\AD{Set}$, but it is actually a
type.  Additionally, Agda has a stratified type system such that
$\AD{Set}$ is an element of $\AD{Set₁}$, $\AD{Set₂}$ an element of
$\AD{Set₃}$ etc. This stratification allows us to avoid Russel type
paradoxes while also quantifying over ever larger objects.

What we generally think of as sets will instead be composite
constructions. We create a function from $\AD{Set}$ to the larger
$\AD{Set₁}$ which is large enough to contain the various types which
are elements of $\AD{Set}$. This provides us with a family of
predicates over the set $\AB{A}$ containing all definable total
functions from $\AB{A}$ into Set.

\begin{code}

record Sets {A : Set} : Set where

  Pred : Set → Set₁
  Pred A = A → Set

  data ⊤ : Set where
    tt : ⊤
    
  data ⊥ : Set where
  
  infix 3 ¬_
  ¬_ : Set → Set
  ¬ A = A → ⊥ 

\end{code}

In Agda, an {\em inhabitant} \AB{A} of a type \AD{S} is denoted
($\AB{A}\,\AO{:}\,\AD{S}$).  This is analogous to the {\em element of}
relation ($A ∈ S$) in set theory. In order to demonstrate
inhabitation, we need to build up a term which can "fit" inside the
type. That is, Agda's type checker should be able to determine that it
is suitable for the type provided. We see above the $\AF{Pred}$ symbol
is given a type, and then a term is provided using a definitional
equality. Agda's type checker will complain if the term is
incompatible with the type (or if Agda is simply unable to figure out
how it might be).

Arrows $(\AO{→})$ in Agda are type constructors which represent the
type of {\em maps} or {\em functions}. An inhabitant of such a type
must be a computable terminating function which given terms of the
type on the left, is able to supply terms of the type on the
right. The termination requirement is necessary to ensure that the
type theory is sound.

A $\AK{record}$ is an object which parameterises some code with
respect to a term of some type. Here the Parameter is $\AB{A}$, given in
curly-braces to denote the fact that we hope Agda can infer it
automatically from context.

$\AK{data}$ declarations allow us to extend our type theory with a new
type having some number of {\em constructors} which are axiomatically
within the type. This will also allow us to deconstruct such sets into
the constituent constructors from whence they must have come.  

We include two sets using $\AK{data}$ declarations, one representing
{\em truth}, $\AD{⊤}$, which has precisely one constructor, and
another representing {\em falsehood}, $\AD{⊥}$ which has no
constructors at all.  We can then construct something akin to a subset
of $\AB{A}$ by mapping elements of $\AB{A}$ into $\AD{⊤}$ and $\AD{⊥}$
in order to model inclusion / exclusion since both $\AD{⊤}$ and
$\AD{⊥}$ are in $\AD{Set}$ and therefore in the family of unary
predicates $\AF{Pred}$. This is essentially the {\em subobject
classifier} approach taken in category theory.

Agda additionally allows us to specify infix, mixfix or prefix terms
in order to make the presentation look more mathematical. The
placement of arguments is given in the declaration by $\_$. The
parsing precedence can also be supplied as with the $\AF{¬}$ function
shown above.

We represent negation constructively as a unary predicate from a type
$\AB{A}$ to $\AD{⊥}$.  That is, to prove the negative, we must supply
a function from our input type to an unprovable constant (The type
$\AD{⊥}$ has no constructors).  This can only be done if $\AB{A}$ is
itself vacuous, that is, during elimination of $\AB{A}$ we can eliminate
all possible cases.  This obviates the need to return anything (which
we cannot do anyhow since $\AD{⊥}$ has no constructors), as we never
get anything in the first place.

\begin{code}
  
  infix 4 _∈_ _∉_

  _∈_ : A → Pred A → Set
  x ∈ P = P x

  _∉_ : A → Pred A → Set
  x ∉ P = ¬ x ∈ P

\end{code} 

With $\AF{\_∈\_}$ we define inclusion as a map, taking an element of
type $\AB{A}$ and a predicate from $\AF{Pred}\;\AB{A}$ which merely
applies the predicate to the element.  In this view, various subsets
of $\AB{A}$ are formed by producing appropriate predicates which
classify which elements belong, and which do not.

\begin{code}
  
  _⊆_ : Pred A → Pred A → Set
  P ⊆ Q = ∀ {x} → x ∈ P → x ∈ Q

  _⇒_ : Pred A → Pred A → Pred A
  P ⇒ Q = λ x → x ∈ P → x ∈ Q
  
\end{code}

We understand $\AB{P}$ to be a subset of \AB{Q} if we are able to
build a map such that if $\AB{P}\;\AB{x}$ holds, then so does
$\AB{Q}\;\AB{x}$.  Similarly we can form a new subset defined by a
predicate which is true precisely when $\AB{P}$ is a subset of
$\AB{Q}$ with the $\AF{\_⇒\_}$ operator.

The other operations of $\AD{∪}$, $\AD{∩}$ etc. are all built
similarly, but we will show a few more examples which are useful for
reading the OWL semantics.

\begin{code}

  ∅ : Pred A 
  ∅ = λ _ → ⊥

  U : Pred A
  U = λ _ → ⊤

  ∁ : Pred A → Pred A
  ∁ P = λ x → x ∉ P

\end{code}

We have the empty set $\AF{∅}$ which is modelled as the type of maps
to the uninhabited type $\AD{⊥}$.  Similarly, $\AF{U}$, which is the
entire universe of discourse, is modelled as the map from $\AB{A}$ to
the type of one constructor $\AD{⊤}$.  We form complement simply by
forming a new predicate which holds precisely when the original
predicate does not hold.

In the actual Agda code we utilise Agda's $\AM{Relation.Unary}$
library which allows us to work over sets stratified at different
levels which gives flexibility while avoiding Russel-type paradoxes
(see \cite{martin1998intuitionistic}).  Utilising this library
requires the specification of level indicies for $\AD{Set}$.  These
indices will prove unimportant to us as we are able to stay at level
zero, however they add another parameter to the definition of
$\AD{Pred}$, such that we must now write: $\AD{Pred}\;\AB{A}\;\AB{ℓ}$,
for some level index $\AB{ℓ}$.  This stratification approach is
something which those interested in OWL's semantics might want to
think of adopting in that it allows metalogical reasoning without
leading to inconsistency.

\section{OWL Semantics}
\label{OWLSemantics}

\AgdaHide{
\begin{code}
open import Data.Empty
open import Function
open import Data.Unit hiding (setoid ; _≤_ )
open import Data.Product
open import Data.Sum
open import Level
open import Relation.Nullary
open import Relation.Unary hiding (Decidable)
open import Relation.Binary using (Setoid; IsEquivalence) 
open import Relation.Binary.Core hiding (_⇒_)
open import Data.Nat hiding (_⊔_) renaming (suc to nsuc ; zero to nzero)
open import Data.Vec hiding (_∈_)

open import Facet
module Main where

\end{code}
}

The definition of OWL semantics\cite{2012OWL} is given with respect to
a fairly large number of interpretation functions in which the theory
is parametric.  We follow this approach and build a module which
parameterises our semantics with respect to the interpretation
functions, a few primitive elements, and a number of laws which must
be satisfied of all theories (for instance the
$\AB{owlTopObjectPropertyLaw}$).

This module parametrisation is {\em syntactic sugar} for
parametrisation of all terms within the module body, in the arguments
of the module.  This allows us to concisely assume a number of facts
which must be present for an instantiation of the module.  This module
can later be instantiated for some given interpretation functions and
data and object domains (provided they also obey the given laws) as we
will demonstrate later in our example in Section~\ref{Example}.  Our
symbols are chosen to reflect the notation given in the OWL direct
semantics as closely as possible.

\begin{code}

module OWL (ClassURI : Set) (IndividualURI : Set)
  (DataTypeURI : Set) (DataPropertyURI : Set)
  (ObjectPropertyURI : Set)
  (Literal : Set)  (Δᴵ : Set)
  (Δᴰ : Set) (_ᶜ : ClassURI → Pred Δᴵ zero)
  (_ᴰᵀ : DataTypeURI → Pred Δᴰ zero)
  (_ᴸᵀ : Literal → Δᴰ) (_ᴵ : IndividualURI → Δᴵ)
  (_ᴰᴾ : DataPropertyURI → Pred (Δᴵ × Δᴰ) zero)
  (_ᴼᴾ : ObjectPropertyURI → Pred (Δᴵ × Δᴵ ) zero) 
  (_ᶠᴬ : Facet × Literal → Pred Δᴰ zero)
  (owlThing : ClassURI) (owlNothing : ClassURI)
  (owlThingLaw : owlThing ᶜ ≡ U)
  (owlNothingLaw : owlNothing ᶜ ≡ ∅)
  (owlTopObjectProperty : ObjectPropertyURI)
  (owlBottomObjectProperty : ObjectPropertyURI)
  (owlTopObjectPropertyLaw : owlTopObjectProperty ᴼᴾ ≡ U)
  (owlBottomObjectPropertyLaw : owlBottomObjectProperty ᴼᴾ ≡ ∅)
  (owlTopDataProperty : DataPropertyURI)
  (owlBottomDataProperty : DataPropertyURI)
  (owlTopDataPropertyLaw : owlTopDataProperty ᴰᴾ ≡ U)
  (owlBottomDataPropertyLaw : owlBottomDataProperty ᴰᴾ ≡ ∅)
  (♯OP : Pred (Δᴵ × Δᴵ) zero → ℕ) (♯DP : Pred (Δᴵ × Δᴰ) zero → ℕ) 
  where

\end{code}

Creating an appropriate data-structure for the syntax of OWL
descriptions in Agda is fairly straightforward and not particularly
enlightening.  We show here only a number of the syntactic elements
which are given by the OWL specification.  Here we have
$\AD{ObjectProperty}$ and $\AD{DataRange}$ specified explicitly as a
data-structure, rather than as a parameter to the model.  This is done
because these data-types are composite due to the possibility of
inverse object properties.

\begin{code}
      
  data ObjectProperty : Set where 
    OP : ObjectPropertyURI → ObjectProperty
    IOP : ObjectPropertyURI → ObjectProperty 

  data DataRange : Set where 
    DataTypeRange : DataTypeURI → DataRange
    DataComplimentOf : DataRange → DataRange
    DataOneOf : ∀ {n} → Vec Literal n → DataRange
    DataTypeRestriction : DataRange → Facet → Literal → DataRange
    
\end{code}

\AgdaHide{

\begin{code}

  data Description : Set where 
    OwlClassURI : ClassURI → Description
    ObjectUnionOf : Description → Description → Description 
    ObjectIntersectionOf : Description → Description → Description 
    ObjectComplementOf : Description → Description
    ObjectOneOf : ∀ {n} → Vec IndividualURI n → Description
    ObjectAllValuesFrom : ObjectProperty → Description → Description
    ObjectSomeValuesFrom : ObjectProperty →  Description → Description 
    ObjectExistsSelf : ObjectProperty → Description
    ObjectHasValue : ObjectProperty → IndividualURI → Description
    ObjectMinCardinality : ℕ → ObjectProperty → Description
    ObjectMaxCardinality : ℕ → ObjectProperty → Description
    ObjectExactCardinality : ℕ → ObjectProperty → Description
    ObjectMinClassCardinality : ℕ → ObjectProperty → Description → Description
    ObjectMaxClassCardinality : ℕ → ObjectProperty → Description → Description
    ObjectExactClassCardinality : ℕ → ObjectProperty → Description → Description
    DataAllValuesFrom : DataPropertyURI → DataRange → Description
    DataSomeValuesFrom : DataPropertyURI → DataRange → Description
    DataHasValue : DataPropertyURI → Literal → Description
    DataMinCardinality : ℕ → DataPropertyURI → Description
    DataMaxCardinality : ℕ → DataPropertyURI → Description
    DataExactCardinality : ℕ → DataPropertyURI → Description
    DataMinRangeCardinality : ℕ → DataPropertyURI → DataRange → Description
    DataMaxRangeCardinality : ℕ → DataPropertyURI → DataRange → Description
    DataExactRangeCardinality : ℕ → DataPropertyURI → DataRange → Description
  
  data ClassAxiom : Set where 
    SubClassOf : Description → Description → ClassAxiom
    EquivalentClasses : Description → Description → ClassAxiom
    DisjointClasses : Description → Description → ClassAxiom
    DisjointUnion : ClassURI → Description → Description → ClassAxiom

  data SubObjectProperty : Set where 
    SubObjectPropertyLift : ObjectProperty → SubObjectProperty
    SubObjectPropertyChain : ObjectProperty → ObjectProperty → SubObjectProperty

  data ObjectPropertyAxiom : Set where 
    SubObjectPropertyOf : SubObjectProperty → ObjectProperty → ObjectPropertyAxiom
    EquivalentObjectProperties : ObjectProperty → ObjectProperty → ObjectPropertyAxiom
    DisjointObjectProperties : ObjectProperty → ObjectProperty → ObjectPropertyAxiom
    InverseObjectProperties : ObjectProperty → ObjectProperty → ObjectPropertyAxiom
    ObjectPropertyDomain : ObjectProperty → Description → ObjectPropertyAxiom 
    ObjectPropertyRange : ObjectProperty → Description → ObjectPropertyAxiom
    FunctionalObjectProperty : ObjectProperty → ObjectPropertyAxiom
    InverseFunctionalObjectProperty : ObjectProperty → ObjectPropertyAxiom
    ReflexiveObjectProperty : ObjectProperty → ObjectPropertyAxiom
    IrreflexiveObjectProperty : ObjectProperty → ObjectPropertyAxiom
    SymetricObjectProperty : ObjectProperty → ObjectPropertyAxiom
    AsymetricObjectProperty : ObjectProperty → ObjectPropertyAxiom
    TransitiveObjectProperty : ObjectProperty → ObjectPropertyAxiom

  data DataPropertyAxiom : Set where 
    SubDataPropertyOf : DataPropertyURI → DataPropertyURI → DataPropertyAxiom
    EquivalentDataProperties : DataPropertyURI → DataPropertyURI → DataPropertyAxiom
    DisjointDataProperties : DataPropertyURI → DataPropertyURI → DataPropertyAxiom
    DataPropertyDomain : DataPropertyURI → Description → DataPropertyAxiom
    DataPropertyRange : DataPropertyURI  → DataRange → DataPropertyAxiom
    FunctionalDataProperty : DataPropertyURI → DataPropertyAxiom
  
  data Fact : Set where 
    SameIndividual : IndividualURI → IndividualURI → Fact
    DifferentIndividuals : IndividualURI → IndividualURI → Fact
    ClassAssertion : ClassURI → IndividualURI → Fact
    ObjectPropertyAssertion : ObjectProperty → IndividualURI → IndividualURI → Fact
    NegativeObjectPropertyAssertion : ObjectProperty → IndividualURI → IndividualURI → Fact
    DataPropertyAssertion : DataPropertyURI → IndividualURI → Literal → Fact
    NegativeDataPropertyAssertion : DataPropertyURI → IndividualURI → Literal → Fact

\end{code}

}

\section{Interpretation} 
\label{Interpretation}

From these syntactic rule definitions we translate into a type which
reflects the semantics.  We see below that our various syntactic
descriptions are built up into a $\AD{Rule}$ data-type.  These in turn
are collected into a $\AD{Theory}$ which may hold any finite number of
rules.

\begin{code}

  data Rule : Set where 
    FactRule : Fact → Rule
    ClassRule : ClassAxiom → Rule
    ObjectPropertyRule : ObjectPropertyAxiom → Rule
    DataProperytRule : DataPropertyAxiom → Rule
  
  Theory : ℕ → Set
  Theory n = Vec Rule n
  
\end{code}

To translate our theory into its appropriate type we need a few
interpretation functions which translate the various syntactic
categories into types.

First, however, we define the meaning of a $\AF{domain}$ and a
$\AF{range}$.  To do this, we use Agda's $\AD{Σ}$ which can be thought
of as an existential quantifier.  This type is inhabited by a pair,
composed of a witness, and a proof that the witness has some property.
In the example of $\AF{domain}$ below, we see that we produce a
predicate, taking an argument of type $(\AB{A}\;\AD{×}\;\AB{B})$ (the
type of cartesian pairs, which in this case is used to model
properties), we then produce a $\AD{Σ}$ type which can be inhabited by
a pair of an element of $\AB{B}$ and a proof that the property $p$
holds over $(\AB{x}\;\AIC{,}\;\AB{y})$.  It is worth noting that we do
not concern ourselves with partial predicates - there must be an
element of the range for an element to be considered part of the
domain, and vice-versa.

\begin{code}

  domain : ∀ {A B : Set} → Pred (A × B) zero  → Pred A zero 
  domain {A} {B} p = λ x → Σ[ y ∈ B ] (x , y) ∈ p

  range : ∀ {A B : Set} → Pred (A × B) zero  → Pred B zero 
  range {A} {B} p = λ y → Σ[ x ∈ A ] (x , y) ∈ p

\end{code}

\section{Interpretation of Descriptions}

The interpretation of $\AD{DataRange}$ produces a predicate over the
data domain type $\AB{Δᴰ}$.  For $\AIC{DataTypeRange}$, we obtain our
interpretation from the data type interpretation function which is a
parameter to the model.  For $\AIC{DataComplementOf}$, we merely form
the complement of the predicate.  The $\AIC{DataOneOf}$ constructor is
slightly more involved.  Here we produce a new predicate as a fold
over a vector of enumerated data types.  The fold is a finite union
which produces a proof obligation to show that an element which
satisfies the predicate must be $\AD{\_≡\_}$ to the literal for some
literal $\AB{c}$.

\begin{code}

  ∣_∣dr : DataRange → Pred Δᴰ zero
  ∣ DataTypeRange t ∣dr = t ᴰᵀ
  ∣ DataComplimentOf r ∣dr = ∁ ∣ r ∣dr 
  ∣ DataOneOf v ∣dr = foldr (λ _ → Pred Δᴰ zero)
                            (λ c p → (λ x → x ≡ c ᴸᵀ) ∪ p) ∅ v 
  ∣ DataTypeRestriction r x x₁ ∣dr = ∣ r ∣dr ∩ (x , x₁) ᶠᴬ
  
\end{code}

The translation of $\AD{ObjectProperty}$ and $\AD{SubObjectProperty}$
is particularly straightforward.  In the case of SubObjectProperty we
use the function $\AF{\_⇒\_}$ which produces a predicate over the type
$(\AB{Δᴵ}\;\AD{×}\;\AB{Δᴵ})$.

\begin{code}

  ∣_∣op : ObjectProperty → Pred (Δᴵ × Δᴵ) zero
  ∣_∣op (OP x) = x ᴼᴾ 
  ∣_∣op (IOP x) = ∁ (x ᴼᴾ)

  ∣_∣sop : SubObjectProperty → Pred (Δᴵ × Δᴵ) zero
  ∣_∣sop (SubObjectPropertyLift p) = ∣ p ∣op 
  ∣_∣sop (SubObjectPropertyChain p q) = ∣ p ∣op ⇒ ∣ q ∣op

\end{code}

We then come to the interpretation of classes.  We omit some of the
interpretations for reasons of space.  Again the structure follows
very closely from the interpretations given in the specification.
Perhaps of note is $\AIC{ObjectAllValuesFrom}$ which produces a proof
obligation that a function is produced which has the entire domain of
individuals as its argument, and $\AIC{ObjectSomeValuesFrom}$ which
produces a $\AD{Σ}$ type requiring that inhabitants provide the
witnessing element from the domain of individuals.

\begin{code}

  ∣_∣c : Description → Pred Δᴵ zero
  ∣ OwlClassURI x ∣c = x ᶜ
  ∣ ObjectUnionOf xc xc₁ ∣c = ∣ xc ∣c ∪ ∣ xc₁ ∣c 
  ∣ ObjectIntersectionOf x x₁ ∣c = ∣ x ∣c ∩ ∣ x₁ ∣c
  ∣ ObjectComplementOf x ∣c = ∁ (∣ x ∣c)
  ∣ ObjectAllValuesFrom p c ∣c =
    λ x → ∀ (y : Δᴵ) → (x , y) ∈ ∣ p ∣op → y ∈ ∣ c ∣c
  ∣ ObjectSomeValuesFrom p c ∣c =
    λ x → Σ[ y ∈ Δᴵ ] ((x , y) ∈ ∣ p ∣op × y ∈ ∣ c ∣c)
    
\end{code}
\AgdaHide{
  \begin{code}
  ∣ ObjectOneOf v ∣c = foldr (λ _ → Pred Δᴵ zero)
    (λ y p → (λ x → x ≡ y ᴵ) ∪ p) ∅ v
  ∣ ObjectExistsSelf p ∣c = λ x → (x , x) ∈ ∣ p ∣op 
  ∣ ObjectHasValue (OP p) v ∣c = λ x → (x , v ᴵ) ∈ p ᴼᴾ
  ∣ ObjectHasValue (IOP p) v ∣c = ∁ (λ x → (x , v ᴵ) ∈ p ᴼᴾ)
  ∣ ObjectMinCardinality n p ∣c = λ x → ♯OP( λ prop → prop ∈ ∣ p ∣op × x ∈ domain ∣ p ∣op ) ≥ n
  ∣ ObjectMaxCardinality n p ∣c = λ x → ♯OP (λ prop → prop ∈ ∣ p ∣op × x ∈ domain ∣ p ∣op) ≤ n
  ∣ ObjectExactCardinality n p ∣c = λ x → ♯OP (λ prop → prop ∈ ∣ p ∣op × x ∈ domain ∣ p ∣op) ≡ n
  ∣ ObjectMinClassCardinality n p c ∣c = λ x → ♯OP( λ prop → (prop ∈ ∣ p ∣op) × x ∈ domain ∣ p ∣op × proj₂ prop ∈ ∣ c ∣c ) ≥ n
  ∣ ObjectMaxClassCardinality n p c ∣c = λ x → ♯OP (λ prop → prop ∈ ∣ p ∣op × x ∈ domain ∣ p ∣op  × proj₂ prop ∈ ∣ c ∣c ) ≤ n
  ∣ ObjectExactClassCardinality n p c ∣c = λ x → ♯OP (λ prop → prop ∈ ∣ p ∣op × x ∈ domain ∣ p ∣op × proj₂ prop ∈ ∣ c ∣c ) ≡ n
  ∣ DataAllValuesFrom p x₁ ∣c =
    λ x → ∀ y → y ∈ p ᴰᴾ → proj₂ y ∈ ∣ x₁ ∣dr
  ∣ DataSomeValuesFrom p x₁ ∣c =
    λ x → Σ[ y ∈ (Δᴵ × Δᴰ) ] (y ∈ p ᴰᴾ → proj₂ y ∈ ∣ x₁ ∣dr)
  ∣ DataHasValue p c ∣c = λ x → Σ[ y ∈ Δᴰ ] (y ≡ c ᴸᵀ × (x , y) ∈ p ᴰᴾ)
  ∣ DataMinCardinality n p ∣c  = λ x → ♯DP (λ prop → prop ∈ p ᴰᴾ × x ∈ domain (p ᴰᴾ)) ≥ n
  ∣ DataMaxCardinality n p ∣c = λ x → ♯DP (λ prop → prop ∈ p ᴰᴾ × x ∈ domain (p ᴰᴾ)) ≤ n
  ∣ DataExactCardinality n p ∣c = λ x → ♯DP (λ prop → prop ∈ p ᴰᴾ × x ∈ domain (p ᴰᴾ)) ≡ n
  ∣ DataMinRangeCardinality n p r ∣c = λ x → ♯DP (λ prop → prop ∈ p ᴰᴾ × x ∈ domain (p ᴰᴾ) × proj₂ prop ∈ ∣ r ∣dr) ≥ n
  ∣ DataMaxRangeCardinality n p r ∣c = λ x → ♯DP (λ prop → prop ∈ p ᴰᴾ × x ∈ domain (p ᴰᴾ) × proj₂ prop ∈ ∣ r ∣dr) ≤ n
  ∣ DataExactRangeCardinality n p r ∣c = λ x → ♯DP (λ prop → prop ∈ p ᴰᴾ × x ∈ domain (p ᴰᴾ) × proj₂ prop ∈ ∣ r ∣dr) ≡ n
  \end{code}
}

It is enlightening to compare these last two to the description of the
OWL direct semantics since the similarity is so apparent.  The
interpretation of these two as follows:

\begin{equation*}
\begin{split}
ObjectAllValuesFrom(P\;C) ⇒ \{ x | ∀ y : ( x, y ) ∈ (P)^{OP} → y ∈ (C)^C \}\\
ObjectSomeValuesFrom(P\;C) ⇒ \{ x | ∃ y : ( x, y ) ∈ (P)^{OP}\;\wedge\;y ∈ (C)^C \}
\end{split}
\end{equation*}

The function $\AF{∣\_∣r}$ is responsible for the interpretation of
rules, which is a map from the $\AD{Rule}$ to $\AD{Set}$ and gives us
the proof obligations required for a single rule. We elide all but the
$\AIC{ClassRule}$ rules, leaving out $\AIC{FactRule}$,
$\AIC{ObjectPropertyRule}$, $\AIC{DataPropertyRule}$ for reasons of
space.

\begin{code}

  ∣_∣r : Rule → Set
  ∣ ClassRule (SubClassOf sub super) ∣r = ∣ sub ∣c ⊆ ∣ super ∣c
  ∣ ClassRule (EquivalentClasses a b) ∣r = ∣ a ∣c ⊆ ∣ b ∣c × ∣ b ∣c ⊆ ∣ a ∣c
  ∣ ClassRule (DisjointClasses a b) ∣r = ∣ a ∣c ∩ ∣ b ∣c ⊆ ∅
  ∣ ClassRule (DisjointUnion c a b) ∣r = c ᶜ ⊆ ∣ a ∣c ∪ ∣ b ∣c × ∣ a ∣c ∩ ∣ b ∣c ⊆ ∅

\end{code}
  \AgdaHide{
  \begin{code}
  ∣ FactRule (SameIndividual x x₁) ∣r = x ᴵ ≡ x₁ ᴵ 
  ∣ FactRule (DifferentIndividuals x x₁) ∣r = x ᴵ ≡ x₁ ᴵ → ⊥
  ∣ FactRule (ClassAssertion C x) ∣r =  x ᴵ ∈ C ᶜ
  ∣ FactRule (ObjectPropertyAssertion (OP x) x₁ x₂) ∣r = (x₁ ᴵ , x₂ ᴵ) ∈ x ᴼᴾ
  ∣ FactRule (ObjectPropertyAssertion (IOP x) x₁ x₂) ∣r = (x₂ ᴵ , x₁ ᴵ) ∈ x ᴼᴾ
  ∣ FactRule (NegativeObjectPropertyAssertion (OP x) x₁ x₂) ∣r = (x₁ ᴵ , x₂ ᴵ) ∉ x ᴼᴾ
  ∣ FactRule (NegativeObjectPropertyAssertion (IOP x) x₁ x₂) ∣r = (x₂ ᴵ , x₁ ᴵ) ∉ x ᴼᴾ
  ∣ FactRule (DataPropertyAssertion p x l) ∣r = (x ᴵ , l ᴸᵀ) ∈ p ᴰᴾ
  ∣ FactRule (NegativeDataPropertyAssertion p x l) ∣r = (x ᴵ , l ᴸᵀ) ∉ p ᴰᴾ
  ∣ ObjectPropertyRule (SubObjectPropertyOf sub super) ∣r = ∣ sub ∣sop ⊆ ∣ super ∣op
  ∣ ObjectPropertyRule (EquivalentObjectProperties a b) ∣r = ∣ a ∣op ⊆ ∣ b ∣op × ∣ b ∣op ⊆ ∣ a ∣op
  ∣ ObjectPropertyRule (DisjointObjectProperties a b) ∣r = ∣ a ∣op ∩ ∣ b ∣op ⊆ ∅
  ∣ ObjectPropertyRule (InverseObjectProperties a b) ∣r =
    ∀ x y → (x , y) ∈ ∣ a ∣op × (y , x) ∈ ∣ b ∣op
  ∣ ObjectPropertyRule (ObjectPropertyDomain p c) ∣r = ∀ x y → (x , y) ∈ ∣ p ∣op → x ∈ ∣ c ∣c
  ∣ ObjectPropertyRule (ObjectPropertyRange p c) ∣r = ∀ x y → (x , y) ∈ ∣ p ∣op → y ∈ ∣ c ∣c
  ∣ ObjectPropertyRule (FunctionalObjectProperty p) ∣r =
    ∀ x y y' → (x , y) ∈ ∣ p ∣op × (x , y') ∈ ∣ p ∣op → y ≡ y'
  ∣ ObjectPropertyRule (InverseFunctionalObjectProperty p) ∣r =
    ∀ x x' y → (x , y) ∈ ∣ p ∣op × (x' , y) ∈ ∣ p ∣op → x ≡ x'
  ∣ ObjectPropertyRule (ReflexiveObjectProperty p) ∣r = ∀ x → (x , x) ∈ ∣ p ∣op
  ∣ ObjectPropertyRule (IrreflexiveObjectProperty p) ∣r = ∀ x → (x , x) ∉ ∣ p ∣op
  ∣ ObjectPropertyRule (SymetricObjectProperty p) ∣r = ∀ x y → (x , y) ∈ ∣ p ∣op × (y , x) ∈ ∣ p ∣op
  ∣ ObjectPropertyRule (AsymetricObjectProperty p) ∣r = ∀ x y → (x , y) ∈ ∣ p ∣op → (y , x) ∉ ∣ p ∣op
  ∣ ObjectPropertyRule (TransitiveObjectProperty p) ∣r =
    ∀ x y z → (x , y) ∈ ∣ p ∣op × (y , z) ∈ ∣ p ∣op → (x , z) ∈ ∣ p ∣op
  ∣ DataProperytRule (SubDataPropertyOf a b) ∣r = a ᴰᴾ ⊆ b ᴰᴾ
  ∣ DataProperytRule (EquivalentDataProperties a b) ∣r = a ᴰᴾ ⊆ b ᴰᴾ × b ᴰᴾ ⊆ a ᴰᴾ
  ∣ DataProperytRule (DisjointDataProperties a b) ∣r = a ᴰᴾ ∩ b ᴰᴾ ⊆ ∅
  ∣ DataProperytRule (DataPropertyDomain p c) ∣r = ∀ x y → (x , y) ∈ p ᴰᴾ → x ∈ ∣ c ∣c
  ∣ DataProperytRule (DataPropertyRange p dr) ∣r = ∀ x y → (x , y) ∈ p ᴰᴾ → y ∈ ∣ dr ∣dr
  ∣ DataProperytRule (FunctionalDataProperty p) ∣r =
    ∀ x y y' → (x , y) ∈ p ᴰᴾ × (x , y') ∈ p ᴰᴾ → y ≡ y'
  \end{code}
}

Lastly $\AF{∣\_∣}$ is the very simple function which takes us from a
vector of rules to the cartesian product of the types associated with
each of these rules, essentially translating the vector rules into a chain of
proof obligations.

\begin{code}

  ∣_∣ : ∀ {n} → Theory n → Set
  ∣ [] ∣ = ⊤
  ∣ x ∷ t ∣ = ∣ x ∣r × ∣ t ∣

\end{code}

\section{Example}
\label{Example}

\AgdaHide{
  \begin{code}
open import Data.Nat
open import Data.Unit
open import Data.Empty
open import Data.Product
open import Data.Vec hiding (_∈_)
open import Relation.Nullary
open import Relation.Unary hiding (Decidable)
open import Relation.Binary.Core
open import Level renaming (zero to lzero ; suc to lsuc)
open import Data.String renaming (_≟_ to _≟s_)
open import Relation.Binary.PropositionalEquality as PropEq
  using (_≡_; refl)
open import Relation.Binary.PropositionalEquality.TrustMe
  \end{code}
}

So how does this work in practice?  We produce a very simple theory in
order to look at the structure of the proof obligations produced.
First, we need to have concrete representatives of all of our
individuals, including classes, data properties, data types etc.

The representation is quite open to us as we must also supply the
interpretation functions and the data and individual domains.  For
simplicity we have represented everything as inductive types.

Our data domain ($\AD{Δᴰ}$) is composed only of strings and natural
numbers, whereas our invidual domain ($\AD{Iᴰ}$) is composed of
classes, object properties, data properties, and individuals.  In this
paper we explicitly give only the data type representing classes and
the interpretation function for individuals, as all the other elements
follow a similar pattern.

\begin{code}

module Example where

  data ClassURI : Set where
    OwlThing : ClassURI
    OwlNothing : ClassURI
    AgentURI : ClassURI
    PersonURI : ClassURI 

  data DataPropertyURI : Set where
    OwlTopDataProperty : DataPropertyURI
    OwlBottomDataProperty : DataPropertyURI
    NameURI : DataPropertyURI

  data ObjectPropertyURI : Set where
    OwlTopObjectProperty : ObjectPropertyURI
    OwlBottomObjectProperty : ObjectPropertyURI
    KnowsURI : ObjectPropertyURI

  data DataTypeURI : Set where
    StringURI : DataTypeURI

  data IndividualURI : Set where
    JackURI : IndividualURI
    JillURI : IndividualURI    

  data Literal : Set where
    natLit : ℕ → Literal
    
  data Δᴰ : Set where
    natural : ℕ → Δᴰ
    string : String → Δᴰ

  data Δᴵ : Set where
    C : ClassURI → Δᴵ
    DP : DataPropertyURI → Δᴵ    
    OP : ObjectPropertyURI → Δᴵ
    I : IndividualURI → Δᴵ

\end{code}

From this point we can begin representing our interpretation
functions.  These interpretation functions take us from a given URI to
a predicate over the appropriate domain.  Here we see that the class
interpretation function takes an $\AIC{OwlThing}$, $\AIC{OwlNothing}$,
$\AIC{AgentURI}$, $\AIC{PersonURI}$ and produces either $\AD{⊤}$ or
$\AD{⊥}$.  That $\AIC{OwlThing}$, $\AIC{OwlNothing}$ be in the domain
is a requirement in order to satisfy the laws necessary to open the
$\AM{OWL}$ module. We will explicitly show only the class, data
property and object property interpretaton functions.

\begin{code}

  _ᶜ : ClassURI → Pred Δᴵ lzero
  _ᶜ OwlThing x = ⊤
  _ᶜ OwlNothing x = ⊥
  _ᶜ AgentURI (C x) = ⊥
  _ᶜ AgentURI (DP x) = ⊥
  _ᶜ AgentURI (OP x) = ⊥
  _ᶜ AgentURI (I JackURI) = ⊤
  _ᶜ AgentURI (I JillURI) = ⊤
  _ᶜ PersonURI (C x) = ⊥
  _ᶜ PersonURI (DP x) = ⊥
  _ᶜ PersonURI (OP x) = ⊥
  _ᶜ PersonURI (I JackURI) = ⊤
  _ᶜ PersonURI (I JillURI) = ⊤

\end{code}

% Here we have the interetations of datatypes and the function which
% maps from literals into the data domain. 

\AgdaHide{
\begin{code}

  _ᴰᵀ : DataTypeURI → Pred Δᴰ lzero
  _ᴰᵀ StringURI (string x) = ⊤
  _ᴰᵀ StringURI (natural n) = ⊥

  _ᴸᵀ : Literal → Δᴰ
  natLit x ᴸᵀ = natural x
  
\end{code}
}

The interprentation function for data and object properties encodes
the triples of our graph.  Each triple ending at $\AD{⊥}$ is known not
to exist. Each ending at $\AD{⊤}$ is considered to be present.  One
can see immediately that the $\AIC{OwlTopDataProperty}$ exists for
everything in the domain and range as the argument $\AB{y}$ is
uninspected.

Our literals $\AS{"Jack"}$ and $\AS{"Jill"}$ are encoded by checking
that the strings are equal to a given string, and producing the proof
of equivalence.

%\AgdaHide{ 
\begin{code}

  _ᴰᴾ : DataPropertyURI → Pred (Δᴵ × Δᴰ) lzero
  _ᴰᴾ OwlTopDataProperty y = ⊤
  _ᴰᴾ OwlBottomDataProperty y = ⊥
  _ᴰᴾ NameURI (C x , proj₂) = ⊥
  _ᴰᴾ NameURI (DP x , proj₂) = ⊥
  _ᴰᴾ NameURI (OP x , proj₂) = ⊥
  _ᴰᴾ NameURI (I JackURI , natural x) = ⊥
  _ᴰᴾ NameURI (I JackURI , string x) with x ≟s "Jack"
  _ᴰᴾ NameURI (I JackURI , string x) | yes p = ⊤
  _ᴰᴾ NameURI (I JackURI , string x) | no ¬p = ⊥
  _ᴰᴾ NameURI (I JillURI , natural x) = ⊥
  _ᴰᴾ NameURI (I JillURI , string x) with x ≟s "Jill"
  _ᴰᴾ NameURI (I JillURI , string x) | yes p = ⊤
  _ᴰᴾ NameURI (I JillURI , string x) | no p = ⊥
  
  _ᴼᴾ : ObjectPropertyURI → Pred (Δᴵ × Δᴵ ) lzero
  _ᴼᴾ OwlTopObjectProperty y = ⊤
  _ᴼᴾ OwlBottomObjectProperty y = ⊥
  _ᴼᴾ KnowsURI (C x , proj₂) = ⊥
  _ᴼᴾ KnowsURI (DP x , proj₂) = ⊥
  _ᴼᴾ KnowsURI (OP x , proj₂) = ⊥
  _ᴼᴾ KnowsURI (I x , C y) = ⊥
  _ᴼᴾ KnowsURI (I x , DP y) = ⊥
  _ᴼᴾ KnowsURI (I x , OP y) = ⊥
  _ᴼᴾ KnowsURI (I x , I y) with x | y
  _ᴼᴾ KnowsURI (I x , I y) | JackURI | JackURI = ⊤
  _ᴼᴾ KnowsURI (I x , I y) | JackURI | JillURI = ⊤
  _ᴼᴾ KnowsURI (I x , I y) | JillURI | JackURI = ⊤
  _ᴼᴾ KnowsURI (I x , I y) | JillURI | JillURI = ⊤

\end{code}
%}

% We supply a completely empty facet interpretation function as we don't
% make use of facets in this particular theory.  Our invidiual URI
% embedding is straightforward in that it just uses the $\AIC{I}$
% constructor to embed in the $\AD{Δᴵ}$ individual domain.

\AgdaHide{
\begin{code} 

  _ᶠᴬ : Facet × Literal → Pred Δᴰ lzero
  _ᶠᴬ x y = ⊥
  
  _ᴵ : IndividualURI → Δᴵ
  x ᴵ = I x

\end{code}
}

With the various interpretation functions, domains and resources
established, we can proceed to open the OWL module which provides us
with the semantic interpretation.  Note here the use of $\AIC{refl}$
which is the proof of correctness of the various laws which OWL must
have satisfied with respect to the top and bottom properties.  These
facts are obviously true to Agda's type checker under subject
reduction so the proof need not be explicit. We have now specialised
our theory with respect to the interpretation functions and domains.

\begin{code}

  open OWL ClassURI IndividualURI DataTypeURI DataPropertyURI
         ObjectPropertyURI Literal
         Δᴵ Δᴰ _ᶜ _ᴰᵀ _ᴸᵀ _ᴵ _ᴰᴾ _ᴼᴾ _ᶠᴬ
         OwlThing OwlNothing refl refl
         OwlTopObjectProperty OwlBottomObjectProperty refl refl
         OwlTopDataProperty OwlBottomDataProperty refl refl
         (λ _ → nzero) (λ _ → nzero)

\end{code}

Finally we are able to see the semantics in action.  We first write
down the rules we would like to be true of our model in
$\AF{myTheory}$.  We do leave an $\AB{\_}$ so that Agda fills in the
appropriate natural number which counts the number of rules we have
provided.  In this case we ask that the following constraints be
fulfilled: $\AIC{AgentURI} ⊆ \AIC{OwlThing}$ $\AIC{PersonURI} ⊆ \AIC{AgentURI}$ 
and that the property $\AIC{KnowsURI}$ has a range and domain of $\AIC{AgentURI}$.

\begin{code}

  myTheory : Theory _
  myTheory = ClassRule (SubClassOf (OwlClassURI AgentURI)
                                   (OwlClassURI OwlThing)) ∷
             ClassRule (SubClassOf (OwlClassURI PersonURI)
                                   (OwlClassURI AgentURI)) ∷
             ObjectPropertyRule (ObjectPropertyRange (OP KnowsURI)
                                                     (OwlClassURI AgentURI)) ∷
             ObjectPropertyRule (ObjectPropertyDomain (OP KnowsURI)
                                                      (OwlClassURI AgentURI)) ∷ []

\end{code} 

We can then apply the $\AF{∣\_∣}$ to $\AF{myTheory}$ and these are
then the obligations which we must fulfill in order to prove that
there is a model.  We show how this is done by filling it with a term
$\AF{testMyTheory}$ which Agda's type checker graciously admits as
filling the type.  We end up with a series of pairs, due to the
cartesian product formed by the translation of vectors into proof
obligations.  At each stage we have to produce a function which fills
the role of the predicate type which results from the description.  In
each case we write out the predicate explicitly $\AF{personIsAgent}$,
$\AF{agentRange}$ and $\AF{agentDomain}$.

If the term provided for $\AF{testMyTheory}$ represented an erroneous
proof then the type checker would reject it, giving an error. The
ability to compile this file is therefore the proof that theory
holds. While we do not demonstrate the functions here for reason of
space, they are in fact contained in the latex file, and type check.

\begin{code}

  testMyTheory : ∣ myTheory ∣
  testMyTheory = (λ x₁ → tt) ,
                 ((λ {x} p → personIsAgent x p) ,
                   ((λ x y p → agentRange x y p) ,
                     ((λ x y p → agentDomain x y p) , tt)))
               where
\end{code}
\begin{code}
                 personIsAgent : ∀ x → x ∈ PersonURI ᶜ → x ∈ AgentURI ᶜ
                 -- ...
\end{code}
\AgdaHide{
\begin{code}
                 personIsAgent (C x) ()
                 personIsAgent (DP x) () 
                 personIsAgent (OP x) ()
                 personIsAgent (I JackURI) p = tt
                 personIsAgent (I JillURI) p = tt
\end{code}
}
\begin{code}
                 agentRange : ∀ x y → (x , y) ∈ KnowsURI ᴼᴾ → y ∈ AgentURI ᶜ
                 -- ...
\end{code}
\AgdaHide{
\begin{code}
                 agentRange (C x) (C x₁) ()
                 agentRange (C x) (DP x₁) ()
                 agentRange (C x) (OP x₁) ()
                 agentRange (C x) (I x₁) ()
                 agentRange (DP x) (C x₁) ()
                 agentRange (DP x) (DP x₁) ()
                 agentRange (DP x) (OP x₁) ()
                 agentRange (DP x) (I x₁) ()
                 agentRange (OP x) (C x₁) ()
                 agentRange (OP x) (DP x₁) ()
                 agentRange (OP x) (OP x₁) ()
                 agentRange (OP x) (I x₁) ()
                 agentRange (I x)  (C x₁) ()
                 agentRange (I x) (OP x₁) ()
                 agentRange (I x) (DP x₁) ()
                 agentRange (I x) (I x₁) x₂ with x | x₁
                 agentRange (I x) (I x₁) x₂ | JackURI | JackURI = tt
                 agentRange (I x) (I x₁) x₂ | JackURI | JillURI = tt
                 agentRange (I x) (I x₁) x₂ | JillURI | JackURI = tt
                 agentRange (I x) (I x₁) x₂ | JillURI | JillURI = tt
\end{code}
}
\begin{code}
                 agentDomain : ∀ x y → (x , y) ∈ KnowsURI ᴼᴾ → x ∈ AgentURI ᶜ
                 -- ...
\end{code}
\AgdaHide{
\begin{code}
                 agentDomain (C x) y ()
                 agentDomain (DP x) y ()
                 agentDomain (OP x) y ()
                 agentDomain (I x) (C x₁) ()
                 agentDomain (I x) (DP x₁) ()
                 agentDomain (I x) (OP x₁) ()
                 agentDomain (I JackURI) (I y) p = tt
                 agentDomain (I JillURI) (I y) p = tt

\end{code}
}
\section{Conclusion and Future Work}
\label{Conclusion}

We have shown how type theory provides a natural framework for
verifying reasoners with respect to OWL's semantics.  This can be used
to improve the quality of reasoner implementation and testing.  We
have shown in a manually worked example how this can be applied, but
we have not yet implemented a reasoner utilising this framework.  In
order to use this technique for testing current reasoners, they would
have to be instrumented to produce the appropriate evidence required
by the proof-obligations for a given ontology.

It is technically possible to demonstrate that a given fragment is
decidable. This is done constructively by creating a function of the
following form:

\begin{code}

  postulate ⟦_⟧ : ∀ {n} → (theory : Theory n) → ∣ theory ∣ ⊎ ¬ ∣ theory ∣

\end{code}

The type of this function says that we can either find an inhabitant
of the theory, or the theory does not have any model whatseover.  This
is a very precise meaning of decidability that provides the model
itself or the proof that no model exists, both of which provide useful
information.  For full OWL such a thing is clearly impossible, so the
type of this function should actually be restricted such that
$\AB{theory}$ is drawn from the appropriate fragment to ensure
decidability.  We are currently developing a reasoner which does
just this for a fragment of OWL DL.

In future work we will use type theory, not only to explore fragments,
but also extensions of OWL semantics, which has been suggested might
be necessary for certain problem
domains\cite{polleres2013rdfs}. Specifically we would like to explore
the extension of OWL DL to include explicit level indicies on classes
which would allow quantification over classes.

Our treatment of cardinality assumes that the external interpretation
functions are somehow able to obtain the size of sets, but in fact
this is not possible given the way that we have encoded predicates. In
the future we hope to leverage the work on finite set representations
in Agda\cite{Firsov2015Dependently} such that these cardinality
constraints can be made directly computable.

It is useful to have formal semantics, but it is even better if the
formal semantics can be operationalised.  We have taken some first
modest steps towards operationalising the semantics of OWL such that
we can reason formally and mechanically using proof assistants.

\section{Acknowledgement}

This research is partially supported by the European Union European Union's
Horizon 2020 research and innovation programme under grant agreement No
644055 (ALIGNED, \url{www.aligned-project.eu}).

\bibliographystyle{plain}
\bibliography{export.bib}

\end{document}
